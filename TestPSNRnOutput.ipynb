{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model\n",
    "This Program is to find out PSNR on test set and provide predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import rawpy\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyReLU(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeakyReLU, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.max(x * 0.2, x)\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        self.UNetConvBlock = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, padding=1),\n",
    "            LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, padding=1),\n",
    "            LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.UNetConvBlock(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = UNetConvBlock(4, 32)   #We have 4 Channel (R, G, B G)- Bayer Pattern Input\n",
    "        self.conv2 = UNetConvBlock(32, 64)\n",
    "        self.conv3 = UNetConvBlock(64, 128)\n",
    "        self.conv4 = UNetConvBlock(128, 256)\n",
    "        self.conv5 = UNetConvBlock(256, 512)\n",
    "        self.up6 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv6 = UNetConvBlock(512, 256)\n",
    "        self.up7 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv7 = UNetConvBlock(256, 128)\n",
    "        self.up8 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv8 = UNetConvBlock(128, 64)\n",
    "        self.up9 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.conv9 = UNetConvBlock(64, 32)\n",
    "        self.conv10 = nn.Conv2d(in_channels=32, out_channels=12, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        pool1 = F.max_pool2d(conv1, kernel_size=2)\n",
    "\n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = F.max_pool2d(conv2, kernel_size=2)\n",
    "\n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = F.max_pool2d(conv3, kernel_size=2)\n",
    "\n",
    "        conv4 = self.conv4(pool3)\n",
    "        pool4 = F.max_pool2d(conv4, kernel_size=2)\n",
    "\n",
    "        conv5 = self.conv5(pool4)\n",
    "\n",
    "        up6 = self.up6(conv5)\n",
    "        up6 = torch.cat([up6, conv4], 1)\n",
    "        conv6 = self.conv6(up6)\n",
    "\n",
    "        up7 = self.up7(conv6)\n",
    "        up7 = torch.cat([up7, conv3], 1)\n",
    "        conv7 = self.conv7(up7)\n",
    "        \n",
    "        up8 = self.up8(conv7)\n",
    "        up8 = torch.cat([up8, conv2], 1)\n",
    "        conv8 = self.conv8(up8)\n",
    "\n",
    "        up9 = self.up9(conv8)\n",
    "        up9 = torch.cat([up9, conv1], 1)\n",
    "        conv9 = self.conv9(up9)\n",
    "\n",
    "        conv10 = self.conv10(conv9)\n",
    "        out = F.pixel_shuffle(conv10, 2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.normal_(0.0, 0.02)\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShortExposure = './Sony/short/'\n",
    "LongExposure = './Sony/long/'\n",
    "ResultFolder = './Results/'\n",
    "\n",
    "listImage = glob.glob(LongExposure + '/1*.ARW')\n",
    "imageList = [int(os.path.basename(singleImage)[0:5]) for singleImage in listImage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detarming Black Lebel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 16383\n"
     ]
    }
   ],
   "source": [
    "imgBlack = rawpy.imread('./Sony/short/00001_00_0.04s.ARW')\n",
    "BlackCh = imgBlack.black_level_per_channel[0]\n",
    "BlackMax = np.max(imgBlack.raw_image)\n",
    "print(BlackCh, BlackMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Bayer pattern 4 channels R,G,B,G before passing to U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbg(imgRaw):\n",
    "    img = imgRaw.raw_image_visible.astype(np.float32)\n",
    "    img = np.maximum(img - BlackCh, 0) / (BlackMax - BlackCh)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    S0, S1 = img.shape[0], img.shape[1]\n",
    "\n",
    "    grbgCh = np.concatenate((img[0:S0:2, 0:S1:2, :], img[0:S0:2, 1:S1:2, :], img[1:S0:2, 1:S1:2, :], img[1:S0:2, 0:S1:2, :]), axis=2)\n",
    "    return grbgCh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPsnr(A, B):\n",
    "    Ch, Hight, Width = A.shape\n",
    "    #sum_psnr = 0 \n",
    "    output = np.clip(B, 0.0, 1.0)\n",
    "    mse = np.sum((A - B)**2)/(Ch*Hight*Width)\n",
    "    psnr =  -10*np.log10(mse)\n",
    "    return psnr\n",
    "    #print(psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Image\n",
    "I took this saving blocks of code from stackoverflow - It can handle with different no of Chanel and cliping functionality. So, I feel comfortable using this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "_errstr = \"Mode is unknown or incompatible with input array shape.\"\n",
    "\n",
    "\n",
    "def bytescale(data, cmin=None, cmax=None, high=255, low=0):\n",
    "    \"\"\"\n",
    "    Byte scales an array (image).\n",
    "    Byte scaling means converting the input image to uint8 dtype and scaling\n",
    "    the range to ``(low, high)`` (default 0-255).\n",
    "    If the input image already has dtype uint8, no scaling is done.\n",
    "    This function is only available if Python Imaging Library (PIL) is installed.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "        PIL image data array.\n",
    "    cmin : scalar, optional\n",
    "        Bias scaling of small values. Default is ``data.min()``.\n",
    "    cmax : scalar, optional\n",
    "        Bias scaling of large values. Default is ``data.max()``.\n",
    "    high : scalar, optional\n",
    "        Scale max value to `high`.  Default is 255.\n",
    "    low : scalar, optional\n",
    "        Scale min value to `low`.  Default is 0.\n",
    "    Returns\n",
    "    -------\n",
    "    img_array : uint8 ndarray\n",
    "        The byte-scaled array.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from scipy.misc import bytescale\n",
    "    >>> img = np.array([[ 91.06794177,   3.39058326,  84.4221549 ],\n",
    "    ...                 [ 73.88003259,  80.91433048,   4.88878881],\n",
    "    ...                 [ 51.53875334,  34.45808177,  27.5873488 ]])\n",
    "    >>> bytescale(img)\n",
    "    array([[255,   0, 236],\n",
    "           [205, 225,   4],\n",
    "           [140,  90,  70]], dtype=uint8)\n",
    "    >>> bytescale(img, high=200, low=100)\n",
    "    array([[200, 100, 192],\n",
    "           [180, 188, 102],\n",
    "           [155, 135, 128]], dtype=uint8)\n",
    "    >>> bytescale(img, cmin=0, cmax=255)\n",
    "    array([[91,  3, 84],\n",
    "           [74, 81,  5],\n",
    "           [52, 34, 28]], dtype=uint8)\n",
    "    \"\"\"\n",
    "    if data.dtype == np.uint8:\n",
    "        return data\n",
    "\n",
    "    if high > 255:\n",
    "        raise ValueError(\"`high` should be less than or equal to 255.\")\n",
    "    if low < 0:\n",
    "        raise ValueError(\"`low` should be greater than or equal to 0.\")\n",
    "    if high < low:\n",
    "        raise ValueError(\"`high` should be greater than or equal to `low`.\")\n",
    "\n",
    "    if cmin is None:\n",
    "        cmin = data.min()\n",
    "    if cmax is None:\n",
    "        cmax = data.max()\n",
    "\n",
    "    cscale = cmax - cmin\n",
    "    if cscale < 0:\n",
    "        raise ValueError(\"`cmax` should be larger than `cmin`.\")\n",
    "    elif cscale == 0:\n",
    "        cscale = 1\n",
    "\n",
    "    scale = float(high - low) / cscale\n",
    "    bytedata = (data - cmin) * scale + low\n",
    "    return (bytedata.clip(low, high) + 0.5).astype(np.uint8)\n",
    "\n",
    "\n",
    "def toimage(arr, high=255, low=0, cmin=None, cmax=None, pal=None, mode=None, channel_axis=None):\n",
    "    \"\"\"Takes a numpy array and returns a PIL image.\n",
    "    This function is only available if Python Imaging Library (PIL) is installed.\n",
    "    The mode of the PIL image depends on the array shape and the `pal` and\n",
    "    `mode` keywords.\n",
    "    For 2-D arrays, if `pal` is a valid (N,3) byte-array giving the RGB values\n",
    "    (from 0 to 255) then ``mode='P'``, otherwise ``mode='L'``, unless mode\n",
    "    is given as 'F' or 'I' in which case a float and/or integer array is made.\n",
    "    .. warning::\n",
    "        This function uses `bytescale` under the hood to rescale images to use\n",
    "        the full (0, 255) range if ``mode`` is one of ``None, 'L', 'P', 'l'``.\n",
    "        It will also cast data for 2-D images to ``uint32`` for ``mode=None``\n",
    "        (which is the default).\n",
    "    Notes\n",
    "    -----\n",
    "    For 3-D arrays, the `channel_axis` argument tells which dimension of the\n",
    "    array holds the channel data.\n",
    "    For 3-D arrays if one of the dimensions is 3, the mode is 'RGB'\n",
    "    by default or 'YCbCr' if selected.\n",
    "    The numpy array must be either 2 dimensional or 3 dimensional.\n",
    "    \"\"\"\n",
    "    data = np.asarray(arr)\n",
    "    if np.iscomplexobj(data):\n",
    "        raise ValueError(\"Cannot convert a complex-valued array.\")\n",
    "    shape = list(data.shape)\n",
    "    valid = len(shape) == 2 or ((len(shape) == 3) and\n",
    "                                ((3 in shape) or (4 in shape)))\n",
    "    if not valid:\n",
    "        raise ValueError(\"'arr' does not have a suitable array shape for \"\n",
    "                         \"any mode.\")\n",
    "    if len(shape) == 2:\n",
    "        shape = (shape[1], shape[0])  # columns show up first\n",
    "        if mode == 'F':\n",
    "            data32 = data.astype(np.float32)\n",
    "            image = Image.frombytes(mode, shape, data32.tostring())\n",
    "            return image\n",
    "        if mode in [None, 'L', 'P']:\n",
    "            bytedata = bytescale(data, high=high, low=low,\n",
    "                                 cmin=cmin, cmax=cmax)\n",
    "            image = Image.frombytes('L', shape, bytedata.tostring())\n",
    "            if pal is not None:\n",
    "                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n",
    "                # Becomes a mode='P' automagically.\n",
    "            elif mode == 'P':  # default gray-scale\n",
    "                pal = (np.arange(0, 256, 1, dtype=np.uint8)[:, np.newaxis] *\n",
    "                       np.ones((3,), dtype=np.uint8)[np.newaxis, :])\n",
    "                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n",
    "            return image\n",
    "        if mode == '1':  # high input gives threshold for 1\n",
    "            bytedata = (data > high)\n",
    "            image = Image.frombytes('1', shape, bytedata.tostring())\n",
    "            return image\n",
    "        if cmin is None:\n",
    "            cmin = np.amin(np.ravel(data))\n",
    "        if cmax is None:\n",
    "            cmax = np.amax(np.ravel(data))\n",
    "        data = (data*1.0 - cmin)*(high - low)/(cmax - cmin) + low\n",
    "        if mode == 'I':\n",
    "            data32 = data.astype(np.uint32)\n",
    "            image = Image.frombytes(mode, shape, data32.tostring())\n",
    "        else:\n",
    "            raise ValueError(_errstr)\n",
    "        return image\n",
    "\n",
    "    # if here then 3-d array with a 3 or a 4 in the shape length.\n",
    "    # Check for 3 in datacube shape --- 'RGB' or 'YCbCr'\n",
    "    if channel_axis is None:\n",
    "        if (3 in shape):\n",
    "            ca = np.flatnonzero(np.asarray(shape) == 3)[0]\n",
    "        else:\n",
    "            ca = np.flatnonzero(np.asarray(shape) == 4)\n",
    "            if len(ca):\n",
    "                ca = ca[0]\n",
    "            else:\n",
    "                raise ValueError(\"Could not find channel dimension.\")\n",
    "    else:\n",
    "        ca = channel_axis\n",
    "\n",
    "    numch = shape[ca]\n",
    "    if numch not in [3, 4]:\n",
    "        raise ValueError(\"Channel axis dimension is not valid.\")\n",
    "\n",
    "    bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n",
    "    if ca == 2:\n",
    "        strdata = bytedata.tostring()\n",
    "        shape = (shape[1], shape[0])\n",
    "    elif ca == 1:\n",
    "        strdata = np.transpose(bytedata, (0, 2, 1)).tostring()\n",
    "        shape = (shape[2], shape[0])\n",
    "    elif ca == 0:\n",
    "        strdata = np.transpose(bytedata, (1, 2, 0)).tostring()\n",
    "        shape = (shape[2], shape[1])\n",
    "    if mode is None:\n",
    "        if numch == 3:\n",
    "            mode = 'RGB'\n",
    "        else:\n",
    "            mode = 'RGBA'\n",
    "\n",
    "    if mode not in ['RGB', 'RGBA', 'YCbCr', 'CMYK']:\n",
    "        raise ValueError(_errstr)\n",
    "\n",
    "    if mode in ['RGB', 'YCbCr']:\n",
    "        if numch != 3:\n",
    "            raise ValueError(\"Invalid array shape for mode.\")\n",
    "    if mode in ['RGBA', 'CMYK']:\n",
    "        if numch != 4:\n",
    "            raise ValueError(\"Invalid array shape for mode.\")\n",
    "\n",
    "    # Here we know data and mode is correct\n",
    "    image = Image.frombytes(mode, shape, strdata)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Part\n",
    "### Select any model for testing. I've saved model for each 100 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv1): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv2): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv3): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv4): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv5): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (up6): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv6): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (up7): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv7): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (up8): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv8): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (up9): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv9): UNetConvBlock(\n",
       "    (UNetConvBlock): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU()\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv10): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "U_Net = UNet()\n",
    "U_Net.load_state_dict(torch.load(ResultFolder + 'ModelSnapshot.pth'))\n",
    "U_Net.to(device)   #Loading to CUda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Test The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##\tImage Names:- 10003_00_0.04s.ARW\t10003_00_0.1s.ARW\t\n",
      "PSNR of these Predicted Images = 25.092809362742344\n",
      "##\tImage Names:- 10006_00_0.04s.ARW\t10006_00_0.1s.ARW\t\n",
      "PSNR of these Predicted Images = 25.661068776958608\n",
      "##\tImage Names:- 10011_00_0.04s.ARW\t10011_00_0.1s.ARW\t\n",
      "PSNR of these Predicted Images = 26.718432771155452\n",
      "#"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    U_Net.eval()\n",
    "    for aImage in imageList:\n",
    "        totalPSNR = 0\n",
    "        PSNRCNT = 0\n",
    "        Names = \"\"\n",
    "        \n",
    "        SEimages = glob.glob(ShortExposure + '%05d_00*.ARW' % aImage)\n",
    "        for k in range(len(SEimages)):\n",
    "            SEpath = SEimages[k]\n",
    "            SEname = os.path.basename(SEpath)\n",
    "            Names = Names+SEname+ \"\\t\"\n",
    "            #print(SEname)\n",
    "            print(\"#\", end=\"\")\n",
    "            LEimages = glob.glob(LongExposure + '%05d_00*.ARW' % aImage)\n",
    "            LEpath = LEimages[0]\n",
    "            LEname = os.path.basename(LEpath)\n",
    "            SEexposure = float(SEname[9:-5])\n",
    "            LEexposure = float(LEname[9:-5])\n",
    "            Exposure = min(LEexposure / SEexposure, 300)\n",
    "\n",
    "            imgRaw = rawpy.imread(SEpath)\n",
    "\n",
    "            ProcessedIm = imgRaw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)    #Process Image with rawpy package\n",
    "            NormalizedIm = np.expand_dims(np.float32(ProcessedIm / 65535.0), axis=0)   #Deviding by 16 bit max no value\n",
    "\n",
    "            LERaw = rawpy.imread(LEpath)\n",
    "            ProcessedIm = LERaw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            LENormalizedIm = np.expand_dims(np.float32(ProcessedIm / 65535.0), axis=0)  #Deviding by 16 bit max no value\n",
    "\n",
    "            \n",
    "            ExpImage = np.expand_dims(rgbg(imgRaw), axis=0) * Exposure\n",
    "            ExpImage = np.minimum(ExpImage, 1.0)\n",
    "            ImageIn = torch.from_numpy(ExpImage).permute(0,3,1,2).to(device)\n",
    "            ImageOut = U_Net(ImageIn)\n",
    "            final = ImageOut.permute(0, 2, 3, 1).cpu().data.numpy()\n",
    "            final = np.minimum(np.maximum(final, 0), 1)\n",
    "\n",
    "            final = final[0, :, :, :]\n",
    "            LENormalizedIm = LENormalizedIm[0, :, :, :]\n",
    "            \n",
    "            PSNR = testPsnr(final, LENormalizedIm)\n",
    "            totalPSNR = totalPSNR+PSNR\n",
    "            PSNRCNT = PSNRCNT+1\n",
    "            \n",
    "            NormalizedIm = NormalizedIm[0, :, :, :]\n",
    "            NormalizedIm = NormalizedIm * np.mean(LENormalizedIm) / np.mean(NormalizedIm)  # scale the low-light image to the same mean of the groundtruth\n",
    "\n",
    "            toimage(final).save(ResultFolder + 'Predicted_Output/%5d_00_%d_out.png' % (aImage, Exposure))\n",
    "            toimage(NormalizedIm).save(ResultFolder + 'Predicted_Output/%5d_00_%d_scale.png' % (aImage, Exposure))\n",
    "            toimage(LENormalizedIm).save(ResultFolder + 'Predicted_Output/%5d_00_%d_gt.png' % (aImage, Exposure))\n",
    "        print(f\"\\tImage Names:- {Names}\\nPSNR of these Predicted Images = {totalPSNR/PSNRCNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
